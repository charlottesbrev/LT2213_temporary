{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2 - Part 2: Inference\n",
    "\n",
    "The lab is an exploration and learning exercise to be done in a group and also in discussion with the teachers and other students.\n",
    "\n",
    "Before starting, please read the following instructions on [how to work on group assignments](https://github.com/sdobnik/computational-semantics/blob/master/README.md).\n",
    "\n",
    "In this part you will work on a problem from the FraCaS test suite. The goal of this problem set is to extend the grammar for Cooper storage from the previous part, apply the sentences to a theorem prover and a model builder, analyse their results and conclude about the inference. Since every sentence may be translated to several formulae there will also be several inference steps and thus several results.\n",
    "\n",
    "\n",
    "\n",
    "### Pre-requisite knowledge\n",
    "\n",
    "From `problem-set-1`:\n",
    "- First order logic\n",
    "- Lambda calculus\n",
    "- Feature unification context free grammar\n",
    "\n",
    "From `problem-set-2-part1.ipynb`:\n",
    "- Cooper storage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This task requires NLTK and Jupyter Notebook (IPython package).\n",
    "import nltk\n",
    "from nltk.grammar import FeatureGrammar\n",
    "from nltk.sem import cooper_storage as cs\n",
    "\n",
    "from utils import display_latex, display_translation, display_tree, display, Markdown\n",
    "from utils2 import sem_parser, evaluate_sentences, syntax, syntax_notv\n",
    "\n",
    "read_expr = nltk.sem.Expression.fromstring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 Extending the grammar [6 marks]\n",
    "\n",
    "Extend the grammar below so that it covers the sentences of the inference problem based on FraCaS problem 057.\n",
    "\n",
    "Several solutions are possible, also some that would not result in entailment. Our lexical knowledge about words leads us how to formalise them in first order logic. Therefore, make sure that you handle the PP attachment in a away that you will be able to show entailments between examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'a Portuguese delegate published the result on climate',\n",
    "    'a Portuguese delegate published a result',\n",
    "    'a Portuguese delegate published the result',\n",
    "    'a Portuguese published a result',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcfg_storage_base = r\"\"\"\n",
    "% start S\n",
    "\n",
    "S[SEM=[CORE=<?subj(?vp)>, STORE=(?b1+?b2)]] -> NP[NUM=?n,SEM=[CORE=?subj, STORE=?b1]] VP[NUM=?n,SEM=[CORE=?vp, STORE=?b2]]\n",
    "\n",
    "Nom[NUM=?n,SEM=?s] -> N[NUM=?n,SEM=?s]\n",
    "\n",
    "VP[NUM=?n,SEM=?s] -> IV[NUM=?n,SEM=?s]\n",
    "VP[NUM=?n,SEM=[CORE=<?v(?obj)>, STORE=(?b1+?b2)]] -> TV[NUM=?n,SEM=[CORE=?v, STORE=?b1]] NP[SEM=[CORE=?obj, STORE=?b2]]\n",
    "VP[NUM=?n,SEM=[CORE=<?v(?pp)(?obj)>, STORE=(?b1+?b2+?b3)]] -> DTV[NUM=?n,SEM=[CORE=?v, STORE=?b1]] NP[SEM=[CORE=?obj, STORE=?b2]] PP[+TO,SEM=[CORE=?pp, STORE=?b3]]\n",
    "\n",
    "PP[+TO, SEM=[CORE=?np, STORE=?b1]] -> P[+TO] NP[SEM=[CORE=?np, STORE=?b1]]\n",
    "\"\"\"\n",
    "\n",
    "fcfg_storage_lexicon = r\"\"\"\n",
    "PropN[NUM=sg,SEM=[CORE=<\\P.P(angus)>, STORE=(/)]] -> 'Angus'\n",
    "PropN[NUM=sg,SEM=[CORE=<\\P.P(cyril)>, STORE=(/)]] -> 'Cyril'\n",
    "PropN[NUM=sg,SEM=[CORE=<\\P.P(irene)>, STORE=(/)]] -> 'Irene'\n",
    "\n",
    "Det[NUM=sg,SEM=[CORE=<\\P Q.all x.(P(x) -> Q(x))>, STORE=(/)]] -> 'every'\n",
    "Det[NUM=sg,SEM=[CORE=<\\P Q.exists x.(P(x) & Q(x))>, STORE=(/)]] -> 'a'\n",
    "\n",
    "N[NUM=sg,SEM=[CORE=<\\x.library(x)>, STORE=(/)]] -> 'library'\n",
    "N[NUM=sg,SEM=[CORE=<\\x.girl(x)>, STORE=(/)]] -> 'girl'\n",
    "N[NUM=sg,SEM=[CORE=<\\x.boy(x)>, STORE=(/)]] -> 'boy'\n",
    "N[NUM=sg,SEM=[CORE=<\\x.book(x)>, STORE=(/)]] -> 'book'\n",
    "\n",
    "IV[NUM=sg,SEM=[CORE=<\\x.smile(x)>, STORE=(/)],TNS=pres] -> 'smiles' \n",
    "\n",
    "TV[NUM=sg,SEM=[CORE=<\\X x.X(\\y.read(x,y))>, STORE=(/)],TNS=pres] -> 'reads'\n",
    "\n",
    "DTV[NUM=sg,SEM=[CORE=<\\Y X x.X(\\z.Y(\\y.give(x,y,z)))>, STORE=(/)],TNS=pres] -> 'gives'\n",
    "\n",
    "P[+to] -> 'to'\n",
    "\"\"\" \n",
    "\n",
    "fcfg_storage_np = r\"\"\"\n",
    "NP[NUM=?n,SEM=[CORE=<\\P.P(@x)>, STORE=(<bo(?np, @x)>+?b1)]] -> PropN[NUM=?n,SEM=[CORE=?np, STORE=?b1]]\n",
    "NP[NUM=?n,SEM=[CORE=<\\P.P(@x)>, STORE=(<bo(?det(?nom), @x)>+?b1+?b2)]] -> Det[NUM=?n,SEM=[CORE=?det, STORE=?b1]] Nom[NUM=?n,SEM=[CORE=?nom, STORE=?b2]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code resolves the readings from the Cooper storage. We collect the readings in a dictionary where the key is a sentence string and the value is a list of readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answers\n",
    "fcfg_storage_answers_1 = r\"\"\"\n",
    "### Replace X with their proper representations\n",
    "N[NUM=sg,SEM=[CORE=<\\x.portugese(x)>, STORE=(/)]] -> 'Portuguese'\n",
    "N[NUM=sg,SEM=[CORE=<\\x.delegate(x)>, STORE=(/)]] -> 'delegate'\n",
    "TV[NUM=sg,SEM=[CORE=<\\X x.X(\\y.publish(x,y))>, STORE=(/)],TNS=pret] -> 'published'\n",
    "Det[SEM=[CORE=<\\Q P.exists x.(Q(x) & P(x) & all y. (Q(y) implies (y=x)))>, STORE=(/)]] -> 'the'\n",
    "N[NUM=sg,SEM=[CORE=<\\x.result(x)>, STORE=(/)]] -> 'result'\n",
    "P[+ON] -> 'on' \n",
    "N[NUM=sg,SEM=[CORE=<\\x.climate(x)>, STORE=(/)]] -> 'climate'\n",
    "## Extend the other missig rules too\n",
    "NP[NUM=?n,SEM=[CORE=<\\P.P(@x)>, STORE=(<bo(?det(?nom1)(?nom2), @x)>+?b1+?b2+?b3)]] -> Det[NUM=?n,SEM=[CORE=?det, STORE=?b1]] Nom[NUM=?n,SEM=[CORE=?nom1, STORE=?b2]]  Nom[NUM=?n,SEM=[CORE=?nom2, STORE=?b3]]\n",
    "#NP[NUM=?n,SEM=[CORE=<\\P.P(@x)>, STORE=(<bo(?det(?nom1(?nom2)), @x)>+?b1+?b2+?b3)]] -> Det[NUM=?n,SEM=[CORE=?det, STORE=?b1]] Nom[NUM=?n,SEM=[CORE=?nom1, STORE=?b2]]  Nom[NUM=?n,SEM=[CORE=?nom2, STORE=?b3]]\n",
    "#PP[+ON, SEM=[CORE=?np, STORE=?b1]] -> P[+ON] NP[SEM=[CORE=?np, STORE=?b1]]\n",
    "\n",
    "#PP[+ON, SEM=[CORE=?np, STORE=?b1]] -> P[+ON] N[NUM=?np, STORE=?b1]\n",
    "PP[SEM=(?p + ?np)] -> P[+ON, SEM=?p] NP[SEM=?np]\n",
    "\"\"\"\n",
    "\n",
    "# this is going to add new rules to the syntax:\n",
    "fcfg_storage = fcfg_storage_base + fcfg_storage_np + fcfg_storage_lexicon + fcfg_storage_answers_1\n",
    "new_syntax = FeatureGrammar.fromstring(fcfg_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. a Portuguese delegate published the result on climate\n",
      "2. a Portuguese delegate published a result\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\"1\": $\\exists\\ x.(result(x)\\ \\land\\ \\exists\\ z_{1}.(portugese(z_{1})\\ \\land\\ delegate(z_{1}))(\\lambda\\ @x2.publish(@x2,x)))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"2\": $\\exists\\ x.(portugese(x)\\ \\land\\ delegate(x))(\\lambda\\ @x2.\\exists\\ x.(result(x)\\ \\land\\ publish(@x2,x)))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. a Portuguese delegate published the result\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\"1\": $\\exists\\ x.(result(x)\\ \\land\\ \\exists\\ z_{2}.(portugese(z_{2})\\ \\land\\ delegate(z_{2}))(\\lambda\\ @x2.publish(@x2,x))\\ \\land\\ \\forall\\ y.(result(y)\\ \\to\\ (y\\ =\\ x)))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"2\": $\\exists\\ x.(portugese(x)\\ \\land\\ delegate(x))(\\lambda\\ @x2.\\exists\\ x.(result(x)\\ \\land\\ publish(@x2,x)\\ \\land\\ \\forall\\ y.(result(y)\\ \\to\\ (y\\ =\\ x))))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. a Portuguese published a result\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\"1\": $\\exists\\ x.(result(x)\\ \\land\\ \\exists\\ z_{3}.(portugese(z_{3})\\ \\land\\ publish(z_{3},x)))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"2\": $\\exists\\ x.(portugese(x)\\ \\land\\ \\exists\\ z_{4}.(result(z_{4})\\ \\land\\ publish(x,z_{4})))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_readings = sem_parser(sentences, new_syntax, verbose=False, is_cs=True)\n",
    "#    'a Portuguese delegate published the result on climate',\n",
    "#    'a Portuguese delegate published a result',\n",
    "#    'a Portuguese delegate published the result',\n",
    "#    'a Portuguese published a result',\n",
    "# print all readings\n",
    "for i, (sent, semreps) in enumerate(sentence_readings.items()):\n",
    "    counter = 0\n",
    "    print(f\"{i+1}. {sent}\")\n",
    "    for semrep in semreps:\n",
    "        counter += 1\n",
    "        display_translation(counter, semrep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a Portuguese delegate published the result on climate': [],\n",
       " 'a Portuguese delegate published a result': [<ExistsExpression exists x.(result(x) & exists z1.(portugese(z1) & delegate(z1))(\\@x2.publish(@x2,x)))>,\n",
       "  <ApplicationExpression exists x.(portugese(x) & delegate(x))(\\@x2.exists x.(result(x) & publish(@x2,x)))>],\n",
       " 'a Portuguese delegate published the result': [<ExistsExpression exists x.(result(x) & exists z2.(portugese(z2) & delegate(z2))(\\@x2.publish(@x2,x)) & all y.(result(y) -> (y = x)))>,\n",
       "  <ApplicationExpression exists x.(portugese(x) & delegate(x))(\\@x2.exists x.(result(x) & publish(@x2,x) & all y.(result(y) -> (y = x))))>],\n",
       " 'a Portuguese published a result': [<ExistsExpression exists x.(result(x) & exists z3.(portugese(z3) & publish(z3,x)))>,\n",
       "  <ExistsExpression exists x.(portugese(x) & exists z4.(result(z4) & publish(x,z4)))>]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure understanding this data structure:\n",
    "sentence_readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Using Prover9 [4 marks in total]\n",
    "\n",
    "Show which readings of (1) entail a reading of (2). **[1 mark]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "Prover9FatalException",
     "evalue": "(FATAL)\n%%ERROR: A term cannot be constructed from the marked string:\n\n\n    exists x ((%%START ERROR%%\\y.%%END ERROR%%\n\nFatal error:  sread_term error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProver9FatalException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bf48737a618e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#c  = read_expr('mortal(socrates)')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprover\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/inference/api.py\u001b[0m in \u001b[0;36mprove\u001b[0;34m(self, goal, assumptions, verbose)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \"\"\"\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massumptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/inference/prover9.py\u001b[0m in \u001b[0;36m_prove\u001b[0;34m(self, goal, assumptions, verbose)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0massumptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         stdout, returncode = self._call_prover9(\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprover9_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massumptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/inference/prover9.py\u001b[0m in \u001b[0;36m_call_prover9\u001b[0;34m(self, input_str, args, verbose)\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mProver9LimitExceededException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrormsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mProver9FatalException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrormsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProver9FatalException\u001b[0m: (FATAL)\n%%ERROR: A term cannot be constructed from the marked string:\n\n\n    exists x ((%%START ERROR%%\\y.%%END ERROR%%\n\nFatal error:  sread_term error"
     ]
    }
   ],
   "source": [
    "# There is something missing in this code. You will have to fix it, before you can run it.\n",
    "#sentences = [\n",
    "#    'a Portuguese delegate published the result on climate',\n",
    "#    'a Portuguese delegate published a result',\n",
    "#    'a Portuguese delegate published the result',\n",
    "#   'a Portuguese published a result',\n",
    "#]\n",
    "from nltk.sem import Expression\n",
    "prover = nltk.Prover9()\n",
    "p1 = read_expr('man(socrates)')\n",
    "p2 = read_expr('all x.(man(x) -> mortal(x))')\n",
    "c  = read_expr('mortal(socrates)')\n",
    "print(prover.prove(c, [p1,p2]))\n",
    "\n",
    "#p1 = read_expr('portuguese(delegate)')\n",
    "#p2 = read_expr('exists x. (portuguese(x) -> publish(x,y)) x.(man(x) -> mortal(x))')\n",
    "#c  = read_expr('mortal(socrates)')\n",
    "\n",
    "# ∃ 𝑥.(𝑥(𝜆 𝑧9.(𝑟𝑒𝑠𝑢𝑙𝑡(𝑧9) ∧ 𝑐𝑙𝑖𝑚𝑎𝑡𝑒(𝑦3) ∧ 𝑜𝑛(𝑧9,𝑦3))) ∧ ∃ 𝑧10.(𝑝𝑜𝑟𝑡𝑢𝑔𝑒𝑠𝑒(𝑧10) ∧ 𝑑𝑒𝑙𝑒𝑔𝑎𝑡𝑒(𝑧10) ∧ 𝑝𝑢𝑏𝑙𝑖𝑠ℎ(𝑧10,𝑥)) ∧ ∀ 𝑦.(𝑦(𝜆 𝑥.(𝑟𝑒𝑠𝑢𝑙𝑡(𝑥) ∧ 𝑐𝑙𝑖𝑚𝑎𝑡𝑒(𝑦3) ∧ 𝑜𝑛(𝑥,𝑦3))) → (𝑥 = 𝑦)))\n",
    "#e1 = 'exists x.(x(\\ y.(result(y)&climate(z)&on(y,z)))&exists v.(portuguese(v)&deledate(v)&publish(v,x))&all w.(w(\\ x.(result(x)&climate(z)&on(x,z))) -> (x=w)))'\n",
    "e1 = 'exists x.((\\ y.(result(y)&climate(z)&on(y,z)))&exists v.(portuguese(v)&deledate(v)&publish(v,x))&all w.((\\ x.(result(x)&climate(z)&on(x,z))) -> (x=w)))'\n",
    "p1 = read_expr(e1)\n",
    "#∃ 𝑥.(𝑟𝑒𝑠𝑢𝑙𝑡(𝑥) ∧ ∃ 𝑧12.(𝑝𝑜𝑟𝑡𝑢𝑔𝑒𝑠𝑒(𝑧12) ∧ 𝑑𝑒𝑙𝑒𝑔𝑎𝑡𝑒(𝑧12) ∧ 𝑝𝑢𝑏𝑙𝑖𝑠ℎ(𝑧12,𝑥)))\n",
    "e2 = 'exists x.(result(x)&exists y. (portuguese(z)&delegate(y)&publish(y,x)))'\n",
    "p2 = read_expr(e2)\n",
    "\n",
    "#∃ 𝑥.(𝑟𝑒𝑠𝑢𝑙𝑡(𝑥) ∧ ∃ 𝑧16.(𝑝𝑜𝑟𝑡𝑢𝑔𝑒𝑠𝑒(𝑧16) ∧ 𝑝𝑢𝑏𝑙𝑖𝑠ℎ(𝑧16,𝑥)))\n",
    "e3 = 'exists x.(result(x)&exists y. (portuguese(y)&publish(y,x)))'\n",
    "c = read_expr(e3)\n",
    "#c  = read_expr('mortal(socrates)')\n",
    "\n",
    "q = prover.prove(c, [p1,p2])\n",
    "print(q)\n",
    "\n",
    "def apply_theorem_prover(premises, goals):\n",
    "    for premise in premises:\n",
    "        for goal in goals:\n",
    "            q = prover.prove(read_expr(premise), read_expr(goal))\n",
    "            print(\"Premise      : %s\" % (premise))\n",
    "            print(\"Goal         : %s\" % (goal))\n",
    "            print(\"Prover result: %s\" % (...))\n",
    "            print(10*'----')\n",
    "            \n",
    "apply_theorem_prover([sentences[0]],[sentences[1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all the readings of (1) entail all the readings of (2)? If not, why not? **[1 mark]**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** Your answer **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which readings of (1) entail a reading of (4). **[1 mark]** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ellipsis' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-335ec22b2fe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# There is something missing in this code. You will have to fix it, before you can run it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mapply_theorem_prover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-74f95c711214>\u001b[0m in \u001b[0;36mapply_theorem_prover\u001b[0;34m(premises, goals)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_theorem_prover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpremises\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpremise\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpremises\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgoal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgoals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Premise      : %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpremise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ellipsis' object is not iterable"
     ]
    }
   ],
   "source": [
    "# There is something missing in this code. You will have to fix it, before you can run it.\n",
    "\n",
    "apply_theorem_prover(...,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all the readings of (1) entail all the readings of (4)? If not, why not? **[1 mark]**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** Your answer **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.3 Using Mace [2 marks in total]\n",
    "\n",
    "Show whether (1) entails (3). **[1 mark]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ellipsis' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0eeac2de9ccb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m'...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mapply_model_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-0eeac2de9ccb>\u001b[0m in \u001b[0;36mapply_model_builder\u001b[0;34m(premises, goals)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_model_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpremises\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgoals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpremise\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpremises\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgoal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgoals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Premise : %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpremise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ellipsis' object is not iterable"
     ]
    }
   ],
   "source": [
    "# There is something missing in this code. \n",
    "\n",
    "def apply_model_builder(premises,goals):\n",
    "    for premise in premises:\n",
    "        for goal in goals:\n",
    "            print(\"Premise : %s\" % (premise))\n",
    "            print(\"Goal    : %s\" % (goal))\n",
    "            mc = nltk.MaceCommand(..., assumptions=...)\n",
    "            ...\n",
    "            print(\"a model:\")\n",
    "            print(mc.valuation)\n",
    "            print(10*'...')\n",
    "\n",
    "apply_model_builder(...,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain why. **[1 mark]**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** Your answer ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marks\n",
    "\n",
    "This part of the assignment has a total of 12 marks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
